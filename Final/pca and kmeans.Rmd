---
title: "Final"
author: "Yuting Weng"
date: "2024-05-15"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Data Preprocessing by Mengdi

```{r, warning=FALSE}
library(tidyverse)

setwd("C:/Users/user/Desktop/Big Data/HW/final")
data <- read.csv("Airbnb_Data.csv")

# delete id and text variables
data <- select(data, -c(id, description, name))
```


```{r}
data$room_type <- as.factor(data$room_type)
data$property_type <- as.factor(data$property_type)
data$bed_type <- as.factor(data$bed_type)
data$cancellation_policy <- as.factor(data$cancellation_policy)
data$city <- as.factor(data$city)
data$host_has_profile_pic <- as.factor(data$host_has_profile_pic)
data$host_identity_verified <- as.factor(data$host_identity_verified)
data$host_response_rate <- as.factor(data$host_response_rate)
data$instant_bookable <- as.factor(data$instant_bookable)


# Convert host_response_rate to numeric by removing the '%' sign
data$host_response_rate <- as.numeric(gsub("%", "", data$host_response_rate))
```

```{r}
# handle amenities variable: transform into multiple columns
data$amenities <- str_replace_all(data$amenities, '[{}"]', '')
amenities_list <- str_split(data$amenities, ",")

all_amenities <- unique(unlist(amenities_list))

for (amenity in all_amenities) {
  data[[amenity]] <- sapply(amenities_list, function(x) amenity %in% x)
}

data <- select(data, -amenities)
```

```{r}
# handle date variables
data$first_review <- as.Date(data$first_review, format="%Y-%m-%d")
data$last_review <- as.Date(data$last_review, format="%Y-%m-%d")
data$host_since <- as.Date(data$host_since, format="%Y-%m-%d")

# transform date variables into more meaningful variables
data$days_since_first_review <- as.numeric(Sys.Date() - data$first_review)
data$days_since_last_review <- as.numeric(Sys.Date() - data$last_review)
data$host_duration <- as.numeric(Sys.Date() - data$host_since)

# delete first_review, last_review, host_since
data <- select(data, -c(first_review, last_review, host_since))
```

```{r}
# turn thumbnail_url into a binary categorical variable
data$has_thumbnail <- ifelse(is.na(data$thumbnail_url) | data$thumbnail_url == "", FALSE, TRUE)

# delete thumbnail_url
data <- select(data, -thumbnail_url)
```

```{r}
count_missing <- function(x) {
  sum(is.na(x) | x == "")
}

# Create a summary of missing values (NA and empty strings) for each column
missing_values_summary <- data %>%
  summarise_all(count_missing) %>%
  gather(key = "variable", value = "missing_count") %>%
  arrange(desc(missing_count))

print(missing_values_summary)
```

```{r}
# Impute the above numerical variables that have missing values with median values
data$host_response_rate[is.na(data$host_response_rate)] <- median(data$host_response_rate, na.rm = TRUE)
data$review_scores_rating[is.na(data$review_scores_rating)] <- median(data$review_scores_rating, na.rm = TRUE)
data$days_since_first_review[is.na(data$days_since_first_review)] <- median(data$days_since_first_review, na.rm = TRUE)
data$days_since_last_review[is.na(data$days_since_last_review)] <- median(data$days_since_last_review, na.rm = TRUE)
data$bathrooms[is.na(data$bathrooms)] <- median(data$bathrooms, na.rm = TRUE)
data$host_duration[is.na(data$host_duration)] <- median(data$host_duration, na.rm = TRUE)
data$beds[is.na(data$beds)] <- median(data$beds, na.rm = TRUE)
data$bedrooms[is.na(data$bedrooms)] <- median(data$bedrooms, na.rm = TRUE)

# Replace missing values with specific values for categorical columns
data$host_has_profile_pic[is.na(data$host_has_profile_pic) | data$host_has_profile_pic == ''] <- 'f'
data$host_identity_verified[is.na(data$host_identity_verified) | data$host_identity_verified == ''] <- 'f'
data$neighbourhood[is.na(data$neighbourhood) | data$neighbourhood == ''] <- 'Unknown'
data$zipcode[is.na(data$zipcode) | data$zipcode == ''] <- 'Unknown'

# Convert to factors
data$neighbourhood <- as.factor(data$neighbourhood)
data$zipcode <- as.factor(data$zipcode)
```

```{r}
# extract numerical variable names
numeric_vars <- c("log_price", "accommodates", "bathrooms", "host_response_rate", 
                  "latitude", "longitude", "number_of_reviews", "review_scores_rating", 
                  "bedrooms", "beds", "days_since_first_review", "days_since_last_review", 
                  "host_duration")

# extract categorical variable names
categorical_vars <- setdiff(names(data), numeric_vars)

# standardize numerical variables
data_numeric <- scale(data[numeric_vars])
data_numeric <- as.data.frame(data_numeric)

# combine standardized numerical variables with categorical variables
data_scale <- cbind(data_numeric, data[categorical_vars])

```

```{r}
names(data) <- make.names(names(data), unique = TRUE)

print(names(data))
```


### More Data Cleaning
```{r}
factor_cols <- names(data_scale)[sapply(data_scale, is.factor)]

# Convert factor columns to numeric values
for (col in factor_cols) {
  data[[col]] <- as.numeric(factor(data[[col]])) - 1
}
```

```{r}
# Identify columns with only TRUE and FALSE values
logical_cols <- sapply(data, function(col) is.logical(col) && all(col %in% c(TRUE, FALSE)))

# Convert logical columns to 0s and 1s
logical_col_names <- names(logical_cols)[logical_cols]
data[logical_col_names] <- lapply(data[logical_col_names], as.integer)
```

```{r}
# Convert "True" and "FALSE" strings to logical
data$cleaning_fee <- tolower(data$cleaning_fee) == "true"

# Convert logical values to numeric 0s and 1s
data$cleaning_fee <- as.integer(data$cleaning_fee)
```



```{r}
# Define categories

Essentials = c("Essentials", "Hangers", "Hair.dryer", "Iron", "First.aid.kit",  "Safety.card", "Lock.on.bedroom.door",  "TV", "Cable.TV", "Bed.linens", "Extra.pillows.and.blankets", "Changing.table")
Facilities = c("Air.conditioning", "Heating", "Breakfast", "Pool", "Gym", "Hot.tub", "Elevator", "Elevator.in.building", "Washer", "Dryer", "Laptop.friendly.workspace")
Parking = c("Free.parking.on.street","Free.parking.on.premises","Paid.parking.off.premises")
Privacy = c("Private.bathroom", "Private.living.room", "Private.entrance")
Family = c("Family.kid.friendly", "Children.s.books.and.toys", "Children.s.dinnerware", "Crib", "High.chair", "Stair.gates", "Window.guards", "Table.corner.guards", "Baby.monitor", "Baby.bath", "Fireplace.guards", "Game.console", "Babysitter.recommendations", "Pack..n.Play.travel.crib")
Safety = c("Fire.extinguisher","Smoke.detector","Indoor.fireplace", "Carbon.monoxide.detector")
Pets = c("Pets.allowed", "Dog.s.", "Cat.s.", "Other.pet.s.", "Pets.live.on.this.property")
Kitchen = c("Kitchen", "Microwave", "Coffee.maker", "Refrigerator", "Dishes.and.silverware", "Dishwasher", "Oven", "Stove", "Cooking.basics", "Hot.water.kettle")
Internet = c("Internet","Wireless.Internet", "Ethernet.connection", "Buzzer.wireless.intercom")
Self_Checkin = c("Self.Check.In", "Lockbox")
Accessibility = c("Wheelchair.accessible", "Wide.clearance.to.bed", "Accessible.height.bed", "Wide.doorway", "Accessible.height.toilet", "Wide.entryway", "Step.free.access", "Ground.floor.access", "Wide.clearance.to.shower...toilet", "Wide.clearance.to.shower.and.toilet", "Wide.hallway.clearance", "Flat.smooth.pathway.to.front.door", "X.smooth.pathway.to.front.door", "Well.lit.path.to.entrance")
Events = c("Suitable.for.events", "Doorman", "Doorman.Entry")
Others = c("Other", "translation.missing..en.hosting_amenity_49", "V106", "Single.level.home","Flat")
Bathroom = c("Bathtub", "Hot.water", "Shampoo", "Bathtub.with.shower.chair", "Handheld.shower.head", "Grab.rails.for.shower.and.toilet", "Body.soap", "Hand.soap", "Bath.towel", "Hand.or.paper.towel", "Toilet.paper")
Outdoor = c("Garden.or.backyard", "Patio.or.balcony", "BBQ.grill", "Lake.access", "Beachfront", "Beach.essentials", "Ski.in.Ski.out", "Path.to.entrance.lit.at.night", "Waterfront")
Smoking = c("Smoking.allowed")
Miscellaneous = c("Luggage.dropoff.allowed","Outlet.covers", "Long.term.stays.allowed", "Firm.mattress", "Pocket.wifi", "Cleaning.before.checkout", "EV.charger", "Keypad", "Smart.lock")


data_new <- data %>%
  mutate(
    Essentials = ifelse(rowSums(select(., all_of(Essentials))) > 0, 1, 0),
    Facilities = ifelse(rowSums(select(., all_of(Facilities))) > 0, 1, 0),
    Parking = ifelse(rowSums(select(., all_of(Parking))) > 0, 1, 0),
    Privacy = ifelse(rowSums(select(., all_of(Privacy))) > 0, 1, 0),
    Family = ifelse(rowSums(select(., all_of(Family))) > 0, 1, 0),
    Safety = ifelse(rowSums(select(., all_of(Safety))) > 0, 1, 0),
    Pets = ifelse(rowSums(select(., all_of(Pets))) > 0, 1, 0),
    Kitchen = ifelse(rowSums(select(., all_of(Kitchen))) > 0, 1, 0),
    Internet = ifelse(rowSums(select(., all_of(Internet))) > 0, 1, 0),
    Self_Checkin = ifelse(rowSums(select(., all_of(Self_Checkin))) > 0, 1, 0),
    Accessibility = ifelse(rowSums(select(., all_of(Accessibility))) > 0, 1, 0),
    Events = ifelse(rowSums(select(., all_of(Events))) > 0, 1, 0),
    Others = ifelse(rowSums(select(., all_of(Others))) > 0, 1, 0),
    Bathroom = ifelse(rowSums(select(., all_of(Bathroom))) > 0, 1, 0),
    Outdoor = ifelse(rowSums(select(., all_of(Outdoor))) > 0, 1, 0),
    Smoking = ifelse(rowSums(select(., all_of(Smoking))) > 0, 1, 0),
    Miscellaneous = ifelse(rowSums(select(., all_of(Miscellaneous))) > 0, 1, 0)
  )

```

```{r}
# Define columns to keep
columns_to_keep <- c("log_price", "property_type", "room_type", "accommodates", "bathrooms", "bed_type", "cancellation_policy", "cleaning_fee", "city", "host_has_profile_pic", "host_identity_verified", "host_response_rate", "instant_bookable", "latitude", "longitude", "neighbourhood", 
"number_of_reviews", "review_scores_rating", "zipcode", "bedrooms", "beds", "Essentials", "Facilities", "Parking", "Privacy", "Family", "Safety", "Pets", "Kitchen", "Internet", "Self_Checkin",  "Accessibility", "Events", "Others", "Bathroom", "Outdoor", "Smoking", "Miscellaneous")

# Create new data frame with only columns to keep
data_new <- data_new %>%
  select(all_of(columns_to_keep))
```








### PCA with only numerical values

```{r}
# Remove the 'log_price' column from data_numeric
data_without_y <- data[numeric_vars][, setdiff(names(data[numeric_vars]), c("log_price"))]

# Perform PCA
pca_result <- prcomp(data_without_y, scale. = TRUE)

# Summary of PCA
summary(pca_result)
```
```{r}
# The scree plot
plot(pca_result, xlab = "Principal Component")
```

```{r}
# Extract the scores of the observations along the principal components
scores <- pca_result$x

# Plot the scores of the observations on the first two principal components
plot(scores[,1], scores[,2], 
     xlab = "Principal Component 1", ylab = "Principal Component 2",
     main = "Scatter Plot of Principal Components")
```

```{r, warning=FALSE}
library(gamlr)
# Extract the first K principal components
pca_data <-predict(pca_result)
pca_df <- as.data.frame(pca_data)

log_price <- data_numeric$log_price

kfits <- lapply(1:12, function(K) glm(log_price~., data = pca_df[, 1:K, drop=FALSE]))

aicc <- sapply(kfits, AICc)
plot(aicc)
```
```{r}
which.min(aicc)
```


```{r}
# GLM on First K Technique
log_price <- data_numeric$log_price
glm <- glm(log_price ~ ., data = pca_df, family = gaussian)
summary(glm)
```
```{r, warning=FALSE}
library(glmnet)
# Lasso Technique
lasso_model <- cv.glmnet(x=pca_data, y=log_price, nfold=20)

coef(lasso_model)
```


### PCA with all columns (transforming catgorical columns into dummy)

```{r}
# Scale the Data
data_scale2 <- scale(data_new)
data_scale2 <- as.data.frame(data_scale2)
```

```{r}
# Remove the 'log_price' column 
data_without_y <- data_scale2[, !names(data_scale2) %in% "log_price"]

# Perform PCA
pca_result <- prcomp(data_without_y, scale. = FALSE)

# Summary of PCA
summary(pca_result)
```
```{r}
# The scree plot
plot(pca_result, xlab = "Principal Component")
```
```{r}
# Extract the scores of the observations along the principal components
scores <- pca_result$x

# Plot the scores of the observations on the first two principal components
plot(scores[,1], scores[,2], 
     xlab = "Principal Component 1", ylab = "Principal Component 2",
     main = "Scatter Plot of Principal Components")
```

```{r, warning=FALSE}
library(gamlr)
# Extract the first K principal components
pca_data <-predict(pca_result)
pca_df <- as.data.frame(pca_data)

log_price <- data_numeric$log_price

kfits <- lapply(1:37, function(K) glm(log_price~., data = pca_df[, 1:K, drop=FALSE]))

aicc <- sapply(kfits, AICc)
plot(aicc)
```

```{r}
which.min(aicc)
```
```{r}
# Calculate the second derivative of the AICc curve
second_derivative <- diff(diff(aicc))

# Find the index of the maximum value in the second derivative
sharpest_point <- which.max(second_derivative)

# Get the corresponding number of principal components
optimal_components <- sharpest_point + 1

# Plot the AICc curve and mark the sharpest point
plot(aicc, type = "l", main = "AICc vs. Number of Components")
points(optimal_components, aicc[optimal_components], col = "red", pch = 16)
text(optimal_components, aicc[optimal_components], labels = paste("K =", optimal_components), pos = 3)
```


#### Using GLM

```{r}
# GLM on First K Technique
log_price <- data_scale2$log_price
glm <- glm(log_price ~ ., data = pca_df[1:35], family = gaussian)
summary(glm)
```

```{r}
# Extract coefficients and their p-values
coefficients <- coef(glm)
p_values <- summary(glm)$coefficients[, "Pr(>|t|)"]

# Filter statistically significant coefficients
significant_coefficients <- coefficients[p_values < 0.05]

# Extract names of significant coefficients
significant_coefficient_names <- names(significant_coefficients)

# Count the number of significant coefficients (p-value < 0.05)
num_significant <- sum(p_values < 0.05)

# Print the number of significant coefficients
print(significant_coefficient_names)
print(num_significant)
```


#### Using Lasso Regression

```{r, warning=FALSE}
library(glmnet)
# Lasso Technique
lasso_model <- cv.glmnet(x=pca_data[, 1:35], y=log_price, nfold=20)

coef(lasso_model)
```


```{r}
# Extract coefficients
coefficients <- coef(lasso_model)

# Extract variable names
variable_names <- rownames(coefficients)[-1]  # Exclude the intercept term

# Find significant coefficients
significant_indices <- which(coefficients[-1, ] != 0)

# Print names of significant coefficients
significant_variable_names <- variable_names[significant_indices]
print(significant_variable_names)


# Number of significant coefficients
num_significant_coefficients <- sum(coefficients != 0)

# Print number of significant coefficients
print(num_significant_coefficients)
```
```{r}
# Predict using the Lasso model
lasso_predictions <- predict(lasso_model, newx = pca_data[, 1:35])

# Calculate mean squared error (MSE)
mse <- mean((lasso_predictions - log_price)^2)

# Calculate mean absolute error (MAE)
mae <- mean(abs(lasso_predictions - log_price))

# Calculate R-squared (R2)
actual_mean <- mean(log_price)
ss_total <- sum((log_price - actual_mean)^2)
ss_residual <- sum((log_price - lasso_predictions)^2)
r_squared <- 1 - (ss_residual / ss_total)

# Print the evaluation metrics
print(paste("Mean Squared Error (MSE):", mse))
print(paste("Mean Absolute Error (MAE):", mae))
print(paste("R-squared (R2):", r_squared))
```






# Kmeans????????

```{r}
data_without_price <- data_scale2[, setdiff(names(data_scale2), c("log_price","zipcode", "latitude","longtitude"))]
```



```{r}
# Define the wssplot function
wssplot <- function(data, nc=15, seed=1234){
  wss <- (nrow(data)-1)*sum(apply(data,2,var))
  for (i in 2:nc){
    set.seed(seed)
    wss[i] <- sum(kmeans(data, centers=i)$withinss)}
  plot(1:nc, wss, type="b", xlab="Number of Clusters",
       ylab="Within groups sum of squares")
  wss
}

# Use the function with the prepared data
wss_values <- wssplot(data_without_price, nc=15, seed=1234)
```
```{r}
library(factoextra)
# Assuming your data is stored in a data frame called "your_data"
sampled_data <- data_without_price[sample(nrow(data_without_price), 10000), ]

# Finding the Optimal Number of Clusters with the Silhouette Method
fviz_nbclust(sampled_data, kmeans, method = "silhouette")
```




```{r}
kmean <- kmeans(data_without_price, 2)
kmean$centers
```


```{r}
library(ggplot2)
library("ggfortify")
autoplot(kmean, data_without_price, frame = TRUE)
```

```{r}
library(ggplot2)

# Data frame containing cluster centers
cluster_centers <- data.frame(
  cluster = c("Cluster 1", "Cluster 2"),  # Cluster labels
  variable = colnames(kmean$centers),     # Variable names
  value = c(kmean$centers[1, ], kmean$centers[2, ])  # Average values for each variable in each cluster
)

# Bar plot
bar_plot <- ggplot(cluster_centers, aes(x = variable, y = value, fill = cluster)) +
  geom_bar(stat = "identity", position = "dodge", width = 0.5) +
  labs(x = "Variable", y = "Average Value", title = "Cluster Profiles") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Radar chart
radar_plot <- ggplot(cluster_centers, aes(x = variable, y = value, color = cluster, group = cluster)) +
  geom_line() +
  geom_point(size = 2) +
  labs(x = NULL, y = NULL, title = "Cluster Profiles") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Display plots
print(bar_plot)
print(radar_plot)
```





### K-Means Cluster
```{r}
kfit <- lapply(5*(1:5), function(k) kmeans(data_scale2,k))
```


```{r}
source("kIC.R")

kaicc <- sapply(kfit,kIC)
kbic <- sapply(kfit,kIC,"B")
```


```{r}
## plot 'em:
par(mfrow=c(1,2))
plot(5*(1:5), kaicc, xlab="K", ylab="IC",
	bty="n", type="l", lwd=2)
abline(v=which.min(kaicc)*5)
plot(5*(1:5), kbic, xlab="K", ylab="IC",
	bty="n", type="l", lwd=2, col=4)
abline(v=which.min(kbic)*5,col=4)
```

```{r}
k_values <- c(5,10,15,20,25)
optimal_k_aicc <- k_values[which.min(kaicc)]
optimal_k_bic <- k_values[which.min(kbic)]
optimal_k_bic
```

```{r}
kmfs <- kfit[[which(k_values==optimal_k_bic)]] 
## interpretation: we can see the words with cluster centers
## highest above zero (these are in units of standard deviation of f)
print(apply(kmfs$centers,1,function(c) colnames(data_scale2)[order(-c)[1:10]]))
## use what you know to interpret these.
```
It looks like a tabular representation showing the top features associated with each cluster generated by the clustering algorithm. Each row corresponds to a cluster, and the columns represent the top features within that cluster.

For example:

In Cluster 1, the top features include "Miscellaneous", "Self_Checkin", "zipcode", "Privacy", "Bathroom", etc.
In Cluster 2, the top features include "Others", "room_type", "zipcode", "neighbourhood", "city", etc.
And so on for the other clusters.



```{r}
## how many people in each?
kmfs$size
```

```{r}
# Assuming kmfs is your k-means result object and data_scale2 is your scaled data frame
# Add the cluster assignments to the original data
data_with_clusters <- data_scale2
data_with_clusters$cluster <- kmfs$cluster

# Create a scatter plot of log_price against clusters
ggplot(data_with_clusters, aes(x = factor(cluster), y = log_price)) +
  geom_boxplot() +
  theme_minimal() +
  labs(x = "Cluster", y = "Log Price", title = "Log Price by Cluster")
```


```{r}
# Perform PCA for dimensionality reduction
pca <- prcomp(data_scale2, scale. = FALSE)

# Get the first two principal components
pc <- pca$x[, 1:2]

# Assign clusters to data points
cluster_assignment <- kmfs$cluster

# Create a data frame with PC scores and cluster assignment
df <- data.frame(PC1 = pc[, 1], PC2 = pc[, 2], Cluster = factor(cluster_assignment))

library(viridis)

# Plot the data points colored by cluster
ggplot(df, aes(x = PC1, y = PC2, color = Cluster)) +
  geom_point() +
  scale_color_viridis(discrete = TRUE) +  # Use viridis color palette
  labs(title = "Clusters in PCA Space", x = "PC1", y = "PC2") +
  theme_minimal()
```









